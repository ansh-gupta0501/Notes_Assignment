# Reserved Concurrency and Provisioned Concurrency


* **Reserved concurrency** = reserve (and cap) a portion of your account’s concurrency pool for a function. Use it to *guarantee* capacity for critical functions or *limit* a noisy function. No extra charge. 
* **Provisioned concurrency** = keep N execution environments pre-initialized (warm) for a *specific function version/alias* to eliminate cold starts. It *costs extra* and can be autoscaled/scheduled. 

---

# 1) What “concurrency” means in Lambda

Concurrency = the number of in-flight (simultaneous) function invocations. For each concurrent request Lambda runs a separate execution environment. Lambda automatically scales environments on demand until you hit the account or function limits. 

# 2) Reserved Concurrency — detailed

What it is

* Reserved concurrency assigns a fixed number of concurrent execution “slots” to a function from your account pool. That reserved number is the **maximum** that function can use and is also reserved (not available to others). 

Key behaviors & consequences

* **Isolation / guarantee**: the reserved slots are effectively taken out of the shared pool — this guarantees that the function can scale up to the reserved amount even if other functions are using the account pool.
* **Cap**: the same number is the function’s **cap** — if invocations exceed it, further requests are throttled. For synchronous callers that results in 429; asynchronous calls are queued and retried by Lambda (with its async retry/backoff behavior). 

* **No extra charge**: reserved concurrency itself does not incur billing. It merely re-partitions your account concurrency. 

* **Set to 0**: you can set reserved concurrency to 0 to intentionally block a function (useful to quarantine buggy functions). 

When to use reserved concurrency

* Protect a mission-critical API from noisy neighbors.
* Prevent a runaway function from consuming all account concurrency (cap cost/DB connections).
* Coordinate with SQS/event sources where you want a max concurrency for downstream systems.

How to configure (console / API)

* Console: Function → Configuration → Concurrency → Reserve concurrency.
* CLI/API: `put-function-concurrency` (see AWS docs). 

Monitoring

* Watch `ConcurrentExecutions`, `Throttles`, and account `UnreservedConcurrentExecutions` CloudWatch metrics. 

# 3) Provisioned Concurrency — detailed

What it is

* Provisioned concurrency **pre-creates** (pre-initializes) execution environments for a *specific function version or alias* so those invocations don’t suffer the usual cold-start initialization. It is intended for latency-sensitive, synchronous workloads (APIs, interactive UX). 

Key behaviors & consequences

* **Version/alias specific**: you attach provisioned concurrency to a version or alias (not to `$LATEST`). Use aliases/versions to migrate warm capacity during deployments. 
* **Warm instances**: initialization (code load, init code) runs during allocation — those environments are billed even if they are idle. Allocation is *not* instantaneous; Lambda may take a minute or two to fully provision requested capacity. 

* **Spillover & throttling**: when all provisioned instances are busy, requests can spill over to standard (reserved or unreserved) concurrency if available; otherwise they will be throttled. Metrics like `ProvisionedConcurrencySpilloverInvocations` tell you how often that happens. 

* **Costs**: provisioned concurrency has its own charge (GB-seconds while it’s enabled) in addition to normal invocation/duration charges. Pricing details are on the Lambda pricing page. 

When to use provisioned concurrency

* Latency-sensitive APIs where cold starts are unacceptable.
* Workloads with predictable traffic (use scheduled scaling) or where you can autoscale provisioned capacity. 

Autoscaling & scheduling

* Use **Application Auto Scaling** to schedule or target-track provisioned concurrency (e.g., schedule up for daytime peak, down at night) so you reduce cost while maintaining low latency. 

# 4) How reserved & provisioned concurrency interact (important practical notes)

* **Different scopes**: reserved concurrency applies to a function (all versions), provisioned concurrency applies to one version/alias. 

* **Ordering / limits**: you cannot allocate *more* provisioned concurrency across versions/aliases than the function’s reserved concurrency — reserved concurrency essentially bounds how much provisioned concurrency you can hand out. If the total provisioned concurrency equals the reserved concurrency, \$LATEST can be effectively throttled. 

* **Example mental model**: account pool → some concurrency may be reserved for specific functions → within a function you may designate some of that reserved capacity as provisioned for a particular version/alias (to keep those instances warm).

# 5) Practical recommendations / best practices

1. Use **reserved concurrency** to protect critical functions and to cap noisy or buggy functions. 

2. Use **provisioned concurrency** only for latency-sensitive workloads — combine with Application Auto Scaling (scheduled/target tracking) to avoid paying for idle warm instances. 

3. Start with a **small buffer** when you provision (AWS suggests \~10% extra headroom) and monitor `ProvisionedConcurrencyUtilization` / `ProvisionedConcurrencySpilloverInvocations`. 

4. Use aliases & versioning for safe rollout of provisioned concurrency (blue/green): create a new version, provision concurrency on an alias, then shift traffic. 

5. Monitor throttles and async retry queues — understand differences between sync (caller sees 429) and async (Lambda queues & retries up to configured limits). 



---
